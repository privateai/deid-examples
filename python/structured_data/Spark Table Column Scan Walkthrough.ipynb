{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dcdbac13-3506-4e27-8192-22d64638e51a",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "# Purpose\n",
    "\n",
    "This notebook demonstrates how to run a full scan of all tables and columns in a spark warehouse to detect PI entities in the columns.\n",
    "The results are then saved into a dataframe for reference\n",
    "\n",
    "## Intended Use\n",
    "\n",
    "This notebook walks through how to scan a spark dataframe column by column to detect PI. Obvisously there are many different ways to accomplish this (some likely faster than doing a full collect on the column as well), so use this example as a quick explainer but you'd want to re-work this for production scale.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3a099a7b-1a93-4598-87d2-dc624ba2d603",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from privateai_client import PAIClient\n",
    "from privateai_client import request_objects\n",
    "api_key = 'YOUR KEY GOES HERE' #NOTE: if you have a container, you'd authenticate via the mechanism you set up\n",
    "client = PAIClient(url=\"https://api.private-ai.com/community/\", api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b2cd0622-c6dd-4a93-832d-ed5af8fbf189",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "client.ping()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fb454a33-45d4-4b84-9c4a-c805812a862d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "list_of_tables = []\n",
    "final_output = []\n",
    "for table in spark.catalog.listTables('privateai'):\n",
    "  print(f\"*********** Analyzing table:{table.name} ****************\")\n",
    "  df = spark.sql(\"select * from {0}.{1}\".format(table.database,table.name))\n",
    "  for col in df.columns:\n",
    "    col_list=df.rdd.map(lambda x: x[col]).collect()\n",
    "    text_req = request_objects.process_text_obj(text=[])\n",
    "    print(f\"************** PROCESSING {col} ************\")\n",
    "    text_req.text.append(f\"{col}: {' | '.join(str(x) for x in col_list)}\")\n",
    "    resp = client.process_text(text_req)\n",
    "    final_output.append(\n",
    "      {\"database\":'privatea0',\n",
    "       \"table\":table.name,\n",
    "       \"column\":col,\n",
    "       \"list\":col_list,\n",
    "       \"full_resp\": resp\n",
    "       }\n",
    "      )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c14e0738-15d8-4a7f-8195-d8fbb3004e2b",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for item in final_output:\n",
    "  item['processed_text'] = item['full_resp'].processed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e51a16fd-df8e-42d2-964d-7d3187ad8163",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "def get_best_label_list(entities_list):\n",
    "  best_label_list = []\n",
    "  for item in entities_list:\n",
    "    best_label_list.append(item['best_label'])\n",
    "  return best_label_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a3bb55f9-3c7f-4243-ae92-c73d410943ab",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "for item in final_output:\n",
    "  item['entities_list'] = get_best_label_list(item['full_resp'].entities[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e1d7ba4b-6fa8-4734-b3a5-67d6c195305d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_create_list = []\n",
    "for item in final_output:\n",
    "  df_create_list.append(\n",
    "    {\n",
    "      \"database\":item['database'],\n",
    "      \"table\":item['table'],\n",
    "      \"column\":item['column'],\n",
    "      \"detected_entities\":item['entities_list']\n",
    "    }\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aed59366-9395-4715-8a38-8b79316881cf",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df = spark.createDataFrame(df_create_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82380b07-a734-4afa-ad03-682dee45d523",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "display(output_df.select(\"database\",\"table\",\"column\",\"detected_entities\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "df9cb62f-0b94-4e97-a332-fa9b80f069ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "output_df.write.saveAsTable(\"detection_output_results\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 2
   },
   "notebookName": "Table Column Scan Walkthrough",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
